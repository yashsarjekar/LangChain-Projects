{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f11463-af7d-44d4-8464-8a10962a2c0b",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b660495-2017-479f-82db-22eb23307a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300c78ef-720b-4d17-a8ad-588e1418d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashsarjekar/Documents/AI_WORK/Langchain/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x176341160> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x176341be0> root_client=<openai.OpenAI object at 0x169aa6270> root_async_client=<openai.AsyncOpenAI object at 0x176341940> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237a9b3e-b5cf-44e1-92d3-31e4ac42e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f59f11c1-22b3-47e1-ae4f-a356ddf91791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence techniques and models designed to generate new content or data that is similar to existing data. Unlike traditional AI systems that might be focused on identifying patterns or making predictions based on input data, generative AI is about creating—whether it be text, images, music, or other forms of media. These systems learn from large datasets and use this knowledge to produce new outputs.\\n\\nSome well-known types of generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These consist of two neural networks—a generator and a discriminator—that work in tandem. The generator creates new data, while the discriminator evaluates its authenticity. Through this adversarial process, the generator improves over time to produce increasingly realistic data.\\n\\n2. **Variational Autoencoders (VAEs):** These are a type of neural network architecture that learns to encode input data into a lower-dimensional space and then reconstruct it. This allows for the generation of new data by sampling from the encoded space.\\n\\n3. **Transformers and Language Models:** Models like GPT (Generative Pre-trained Transformer) for text generation or DALL-E for images use transformer architecture to generate coherent and contextually appropriate content, whether in text or visual form.\\n\\nGenerative AI has diverse applications across various fields, such as creating realistic images, generating human-like text responses, composing music, designing products, and even generating code. It's a rapidly evolving field with significant potential but also raises discussions about the ethical implications, such as authenticity, copyright issues, and potential misuse.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 313, 'prompt_tokens': 13, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-Cr8A906FAa8gilRqi4UFZkwF7SjQS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b5c38-f793-74a1-a1b0-2694a26c96c4-0' usage_metadata={'input_tokens': 13, 'output_tokens': 313, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d45224c-4b0b-4371-8dba-937b984f3735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cbfce8-3efc-4cd3-af85-f8ad5d6c07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a comprehensive toolkit introduced by LangChain to assist developers in building, evaluating, and monitoring applications powered by language models. It encompasses features for both large language models (LLMs) and LangChain chains, aiming to enhance their development through performance monitoring and evaluation. Key functionalities include observability tools to track how applications interact with LLMs, evaluation metrics to assess the quality of outputs, and various integrations that support efficient development workflows.\\n\\nLangsmith is designed to support a range of tasks including debugging, improving model outputs, and understanding the performance trends of language models within applications. By providing these tools, Langsmith helps developers optimize their use of language models, resulting in more robust and reliable applications. For accessibility and ease of use, Langsmith is available as a hosted platform as well as a self-hosted containerized solution.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 33, 'total_tokens': 199, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-Cr8EKNmVkFCS2B3CAcVBPtYAF2pLt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b5c3c-ec10-7d12-b11d-2572e46fed72-0' usage_metadata={'input_tokens': 33, 'output_tokens': 166, 'total_tokens': 199, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71948182-4ece-4c30-90c7-e442467a9eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c038cb-b0db-457e-a16d-57fd13eae0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a suite of tools and services designed to enhance the development and performance of applications that utilize large language models (LLMs) and generative AI. It is part of the Langchain ecosystem, which provides developers with tools for building applications powered by these advanced models. Langsmith focuses specifically on the observability, monitoring, and evaluation of such applications, helping developers understand and optimize how their language models behave in real-world scenarios.\n",
      "\n",
      "Key features of Langsmith typically include:\n",
      "\n",
      "1. **Tracing**: Langsmith allows developers to trace the inputs and outputs of their language models across multiple runs. This feature helps in debugging and understanding the flow of data within the application.\n",
      "\n",
      "2. **Evaluation**: It provides functionalities to assess the performance of LLMs against specific metrics or benchmarks, enabling developers to gauge the effectiveness of their models.\n",
      "\n",
      "3. **Monitoring**: With Langsmith, developers can continuously monitor deployed models to ensure they perform as expected, letting them pinpoint performance issues or drifts over time.\n",
      "\n",
      "4. **Integration**: The suite is designed to work seamlessly with the existing Langchain tools, providing a comprehensive environment for building, testing, and deploying generative AI applications.\n",
      "\n",
      "In summary, Langsmith is aimed at developers working with language models, providing essential tools to support the entire lifecycle of AI application development from building and testing to deploying and maintaining robust and effective AI systems.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fdec68-5545-4e77-b046-62bf153a7eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
